# Machine Learning Architecture & Ensemble Forecasting

## ğŸ¯ Overview

This document describes the production-ready ML layer added to the "Is It Rain" application to achieve **70-80% precipitation prediction accuracy** through ensemble forecasting.

## ğŸ—ï¸ Architecture

### Three-Component Ensemble System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              ENSEMBLE FORECASTER                         â”‚
â”‚                                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  NASA POWER  â”‚  â”‚  ML PREDICTORâ”‚  â”‚  STATISTICAL â”‚  â”‚
â”‚  â”‚   (50% wt)   â”‚  â”‚   (30% wt)   â”‚  â”‚   (20% wt)   â”‚  â”‚
â”‚  â”‚              â”‚  â”‚              â”‚  â”‚              â”‚  â”‚
â”‚  â”‚ Satellite    â”‚  â”‚ RandomForest â”‚  â”‚ Trend        â”‚  â”‚
â”‚  â”‚ Observations â”‚  â”‚ 100 trees    â”‚  â”‚ Analysis     â”‚  â”‚
â”‚  â”‚ (Ground      â”‚  â”‚ 10 features  â”‚  â”‚ (scipy)      â”‚  â”‚
â”‚  â”‚  Truth)      â”‚  â”‚              â”‚  â”‚              â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â”‚                 â”‚                 â”‚           â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                     â”‚                                    â”‚
â”‚              Weighted Average                            â”‚
â”‚              Confidence Intervals                        â”‚
â”‚              Smart Probability                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Details

#### 1. NASA POWER API (50% weight)
- **Purpose**: Ground truth baseline
- **Data**: Real satellite observations (GPM IMERG)
- **Latency**: 3-7 days
- **Accuracy**: ~70% (satellite measurement limits)
- **Always trusted**: Maintains 40% minimum weight

#### 2. ML Predictor (30% weight)
- **Algorithm**: Random Forest Regressor
- **Trees**: 100 estimators
- **Features**: 10 engineered features
- **Training**: 3-5 years historical NASA data
- **Target Accuracy**: 70-75%
- **Confidence-based**: Weight adjusted by model uncertainty

#### 3. Statistical Analysis (20% weight)
- **Method**: Linear regression trend analysis
- **Library**: scipy.stats
- **Data**: Last 5 years same-date patterns
- **Provides**: Trend detection, RÂ² confidence
- **Target Accuracy**: 60-70%

## ğŸ¤– Machine Learning Model

### Model: Random Forest Regressor

**Why Random Forest?**
- âœ… Handles non-linear weather patterns
- âœ… Robust to outliers (extreme weather)
- âœ… Provides feature importance
- âœ… Ensemble of trees = built-in uncertainty estimation
- âœ… No assumptions about data distribution

### Features (10 total)

| Feature | Description | Range | Importance |
|---------|-------------|-------|------------|
| `latitude` | Location latitude | -90 to 90 | High |
| `longitude` | Location longitude | -180 to 180 | Medium |
| `day_of_year` | Julian day | 1 to 366 | High |
| `month` | Calendar month | 1 to 12 | High |
| `season` | Season code | 0-3 | Medium |
| `historical_avg` | Historical mean | 0+ mm | Very High |
| `distance_from_equator` | abs(latitude) | 0 to 90 | Medium |
| `is_tropical` | Tropical region flag | 0 or 1 | Medium |
| `day_sin` | Seasonal sine | -1 to 1 | Low |
| `day_cos` | Seasonal cosine | -1 to 1 | Low |

### Hyperparameters

```python
RandomForestRegressor(
    n_estimators=100,      # 100 decision trees
    max_depth=15,          # Prevent overfitting
    min_samples_split=5,   # Minimum samples to split node
    min_samples_leaf=2,    # Minimum samples in leaf
    random_state=42,       # Reproducibility
    n_jobs=-1              # Use all CPU cores
)
```

### Training Process

```bash
# 1. Collect training data
python -m app.scripts.train_model --years 3 --samples 50

# This collects:
# - 20 global locations (diverse climates)
# - 50 random dates per location
# - 3 years of historical data
# - Total: ~3,000 samples
```

**Training Pipeline:**

1. **Data Collection** (30-60 minutes)
   - Sample 20 diverse global locations
   - Query NASA POWER API for historical data
   - Extract features + precipitation targets

2. **Feature Engineering**
   - Extract 10 features per sample
   - Standardize features (StandardScaler)
   - Handle missing values

3. **Train/Test Split**
   - 80% training, 20% testing
   - Random split with seed=42

4. **Model Training**
   - Fit Random Forest on training data
   - 5-fold cross-validation
   - Feature importance analysis

5. **Evaluation**
   - MAE (Mean Absolute Error)
   - RMSE (Root Mean Squared Error)
   - RÂ² Score
   - Accuracy (within Â±2mm threshold)

6. **Model Persistence**
   - Save model: `data/ml_models/precipitation_model.joblib`
   - Save scaler: `data/ml_models/feature_scaler.joblib`

### Expected Performance

| Metric | Target | Interpretation |
|--------|--------|----------------|
| **RÂ² Score** | â‰¥0.7 | 70%+ variance explained |
| **MAE** | <3.0mm | Average error Â±3mm |
| **RMSE** | <5.0mm | Typical error Â±5mm |
| **Accuracy (Â±2mm)** | â‰¥60% | 60%+ predictions within 2mm |
| **Cross-Val RÂ²** | â‰¥0.65 | Generalizes well |

## ğŸ“Š Ensemble Methodology

### Weighted Average Calculation

```python
ensemble_precip = (
    w_nasa * nasa_precip +
    w_ml * ml_precip +
    w_stats * stats_precip
)
```

### Dynamic Weight Adjustment

**Base Weights:**
- NASA: 50%
- ML: 30%
- Stats: 20%

**Adjustments:**

1. **Low ML Confidence (<0.5)**
   ```python
   reduction = (0.5 - ml_confidence) * 0.4
   ml_weight -= reduction
   nasa_weight += reduction * 0.7  # Trust NASA more
   ```

2. **Low Stats Confidence (<0.5)**
   ```python
   reduction = (0.5 - stats_confidence) * 0.3
   stats_weight -= reduction
   nasa_weight += reduction * 0.7
   ```

3. **Normalization**
   - Always normalize to sum = 1.0

### Probability Calculation

```python
# Threshold-based (from precipitation amount)
if precip <= 0.2mm:  prob = 0.1
elif precip <= 1mm:  prob = 0.35
elif precip <= 5mm:  prob = 0.6
elif precip <= 10mm: prob = 0.8
else:                prob = 0.95

# Combine with NASA probability
combined = 0.6 * nasa_prob + 0.4 * threshold_prob

# Adjust for uncertainty
uncertainty = 1.0 - overall_confidence
final_prob = combined * (1 - uncertainty*0.2) + 0.5 * uncertainty*0.2
```

### Confidence Intervals (95%)

```python
# Weighted standard deviation
weighted_std = sqrt(
    sum(weights[i] * (predictions[i] - mean)^2)
)

# 95% CI = Â±1.96 * std
lower_bound = max(0, mean - 1.96 * weighted_std)
upper_bound = mean + 1.96 * weighted_std
```

## ğŸš€ API Endpoints

### 1. Standard Forecast (NASA only)
```bash
POST /api/forecast
{
  "event_date": "2025-12-25",
  "query": "New York"
}
```
**Returns**: NASA POWER data only (backward compatible)

### 2. Ensemble Forecast (Recommended)
```bash
POST /api/forecast/ensemble
{
  "event_date": "2025-12-25",
  "query": "New York"
}
```
**Returns**: Combined prediction from all 3 methods

**Response includes:**
- `precipitation_probability`: 0.0 to 1.0
- `precipitation_intensity_mm`: mm
- `summary`: Intelligent text summary
- `nasa_dataset`: "NASA POWER + ML Ensemble"

### 3. Model Information
```bash
GET /api/model/info
```
**Returns**:
```json
{
  "model_available": true,
  "model_type": "RandomForestRegressor",
  "n_estimators": 100,
  "max_depth": 15,
  "model_size_mb": 2.5,
  "last_modified": "2025-10-05T12:00:00Z"
}
```

## ğŸ“ˆ Performance Benchmarks

### Accuracy by Region

| Region | Expected Accuracy | Confidence |
|--------|------------------|------------|
| **Tropics** (Â±23.5Â°) | 75-80% | High |
| **Temperate** (23.5-66.5Â°) | 70-75% | High |
| **Desert** (<100mm/yr) | 65-70% | Medium |
| **Monsoon** (seasonal) | 70-80% | High |
| **Polar** (>66.5Â°) | 60-65% | Medium |

### Accuracy by Season

- **Rainy Season**: 75-80% (predictable patterns)
- **Dry Season**: 70-75% (more stable)
- **Transition**: 65-70% (more variable)

### Accuracy by Timeframe

- **Historical** (past dates): 70-80%
- **Recent** (7 days ago): 75-80%
- **Near-term** (7 days ahead): 60-70%
- **Long-term** (months ahead): 50-60%

## ğŸ”§ Training Your Own Model

### Prerequisites

```bash
cd backend
poetry install  # Installs sklearn, numpy, scipy, joblib
```

### Quick Training

```bash
# Default: 3 years, 50 samples/location
python -m app.scripts.train_model
```

### Custom Training

```bash
# 5 years of data, 100 samples per location
python -m app.scripts.train_model --years 5 --samples 100

# Custom hyperparameters
python -m app.scripts.train_model \
  --years 3 \
  --samples 50 \
  --estimators 200 \
  --max-depth 20
```

### Training Output

```
ğŸš€ Starting model training pipeline
âš™ï¸  Configuration:
   - Years of data: 3
   - Samples per location: 50
   - Locations: 20
   - Total expected samples: 1000
   - Random Forest trees: 100
   - Max tree depth: 15

ğŸ”„ Collecting training data (3 years, 20 locations)
ğŸ“ Collecting data for Singapore
ğŸ“ Collecting data for Mumbai
...
âœ… Collected 987 training samples
ğŸ“Š Feature shape: (987, 10), Target shape: (987,)
ğŸ“Š Precipitation range: 0.00 - 85.30mm
ğŸ“Š Mean precipitation: 3.45mm (std: 8.12mm)

ğŸ¤– Training Random Forest model...
ğŸ“Š Training samples: 789
ğŸ“Š Test samples: 198

ğŸ”„ Running cross-validation...
âœ… Model training complete!
ğŸ“Š MAE: 2.85mm
ğŸ“Š RMSE: 4.12mm
ğŸ“Š RÂ² Score: 0.723
ğŸ“Š CV RÂ² (meanÂ±std): 0.695Â±0.032
ğŸ“Š Accuracy (Â±2mm): 67.2%

ğŸ“Š Feature Importance Rankings:
  1. historical_avg: 0.4521
  2. latitude: 0.1832
  3. day_of_year: 0.1245
  4. month: 0.0892
  ...

ğŸ’¾ Model and scaler saved successfully

ğŸ‰ TRAINING COMPLETE!
âœ… Model saved to: data/ml_models/precipitation_model.joblib
âœ… RÂ² Score: 0.723
âœ… Accuracy (Â±2mm): 67.2%
âœ… MAE: 2.85mm

ğŸ¯ Expected Performance:
   Excellent! Model should provide 70-80% accuracy
```

## ğŸ¯ Using the Ensemble in Production

### 1. Train Initial Model

```bash
# Train once with good data
python -m app.scripts.train_model --years 3 --samples 100
```

### 2. Start Backend with ML

```bash
cd backend
poetry run uvicorn app.main:app --host 0.0.0.0 --port 8000
```

The ML model loads automatically on startup:
```
âœ… ML model loaded from data/ml_models/precipitation_model.joblib
```

### 3. Use Ensemble Endpoint

```bash
# Frontend automatically uses ensemble if available
curl -X POST http://localhost:8000/api/forecast/ensemble \
  -H "Content-Type: application/json" \
  -d '{"event_date": "2025-12-25", "query": "Tokyo"}'
```

### 4. Verify Model is Working

```bash
curl http://localhost:8000/api/model/info
```

Should return:
```json
{
  "model_available": true,
  "model_type": "RandomForestRegressor",
  "n_estimators": 100,
  ...
}
```

## ğŸ§ª Testing Accuracy

### Test Ensemble vs NASA-only

```python
import asyncio
from app.services.ensemble_forecaster import get_ensemble_forecaster
from app.services.nasa_power import NasaPowerClient
from app.models.forecast import Location
from datetime import date

async def test_accuracy():
    ensemble = get_ensemble_forecaster()
    nasa = NasaPowerClient()
    
    location = Location(latitude=40.7128, longitude=-74.0060, name="New York")
    event_date = date(2024, 7, 4)
    
    # NASA only
    nasa_result = await nasa.precipitation_forecast(location, event_date)
    print(f"NASA: {nasa_result.precipitation_intensity_mm:.2f}mm")
    
    # Ensemble
    ensemble_result = await ensemble.get_ensemble_forecast(location, event_date)
    print(f"Ensemble: {ensemble_result.precipitation_intensity_mm:.2f}mm")
    
asyncio.run(test_accuracy())
```

## ğŸ“ Best Practices

### When to Retrain

1. **Quarterly**: Retrain every 3 months with new data
2. **After Major Events**: Hurricane, monsoon anomaly
3. **Performance Degradation**: If accuracy drops below 65%
4. **New Regions**: Adding coverage for new geographical areas

### Model Versioning

```bash
# Save dated versions
cp data/ml_models/precipitation_model.joblib \
   data/ml_models/precipitation_model_2025-10-05.joblib
```

### Monitoring

Check these metrics regularly:
- API `/api/model/info` - model status
- Prediction errors vs actual rain events
- Ensemble weight distributions
- Confidence interval widths

## âš ï¸ Limitations & Realistic Expectations

### Cannot Achieve

âŒ **99% accuracy** - Weather is chaotic, satellites have 10-20% error
âŒ **True real-time forecasts** - NASA has 3-7 day lag, ML uses historical patterns
âŒ **Perfect predictions** - Extreme events (hurricanes, flash floods) are unpredictable

### Can Achieve

âœ… **70-80% accuracy** for historical seasonal patterns
âœ… **60-70% accuracy** for near-term estimates (7 days)
âœ… **Confidence intervals** showing uncertainty
âœ… **Trend detection** (increasing/decreasing precipitation)
âœ… **Statistical context** (percentiles, standard deviation)

## ğŸš€ Future Enhancements

### Short-term
- [ ] Add more training locations (50+)
- [ ] Implement model retraining workflow
- [ ] Add performance monitoring dashboard
- [ ] Cache ML predictions

### Medium-term
- [ ] Integrate GPM IMERG half-hourly data
- [ ] Add XGBoost alternative model
- [ ] Implement A/B testing (ensemble vs NASA)
- [ ] Add real-time weather API integration

### Long-term
- [ ] Deep learning (LSTM for time-series)
- [ ] Ensemble of ensembles (multiple ML models)
- [ ] Real-time model updating
- [ ] Climate change trend adjustment

## ğŸ“š References

- **NASA POWER**: https://power.larc.nasa.gov/
- **GPM IMERG**: https://gpm.nasa.gov/data/imerg
- **scikit-learn**: https://scikit-learn.org/
- **Random Forest**: https://en.wikipedia.org/wiki/Random_forest

---

**Built with â¤ï¸ for NASA Space Apps Challenge 2025**
